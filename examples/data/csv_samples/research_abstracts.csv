PaperID,Title,Authors,Year,Abstract,Keywords
R001,Novel Approaches to Semantic Linking,Smith J; Doe A,2023,"This paper explores new algorithms for identifying semantic links between disparate text segments using graph theory and attention mechanisms. Results show improved performance over baseline methods.","semantic linking, graph theory, attention, nlp"
R002,Graph-Based Knowledge Discovery,Chen L; Lee B,2022,"We propose a framework for knowledge discovery based on constructing and analyzing large-scale semantic graphs. Community detection reveals thematic clusters.","knowledge graph, discovery, community detection, text mining"
R003,Understanding Attention in Transformers,Patel S,2023,"A deep dive into the self-attention and cross-attention mechanisms within Transformer models and their role in capturing contextual information for natural language understanding.","transformers, attention mechanism, nlp, deep learning"
R004,Challenges in Document Chunking for AI,Miller P; Garcia K,2021,"This work reviews common document chunking strategies and highlights challenges in preserving semantic coherence, proposing a new context-aware method.","document chunking, nlp, semantic coherence, ai"